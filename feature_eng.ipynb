{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdAJ0bAo7IDuv0DjaN5hO6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BMjsxwZCaoLb"},"outputs":[],"source":["1.  What is a parameter?\n","-   A parameter is a value or variable that defines characteristics of a mathematical model or function. In machine learning, parameters are the values learned by a model (e.g., weights in linear regression or coefficients in neural networks).\n","2.  What is correlation?\n","-   Correlation measures the relationship between two variables. A positive correlation means that as one variable increases, the other tends to increase, while a negative correlation means that as one increases, the other decreases. It ranges from -1 (perfect negative) to +1 (perfect positive).\n","    What does negative correlation mean?\n","-   Negative correlation occurs when two variables move in opposite directions. For example, if higher temperatures correlate with lower energy consumption, that's a negative correlation.\n","3.  Define Machine Learning. What are the main components in Machine Learning?\n","-   Machine Learning is a field of AI that enables computers to learn patterns and make predictions without explicit programming. Key components include:\n","    Datasets: The raw data used for training and testing.\n","    Algorithms: Methods to build the model (e.g., decision trees, neural networks).\n","    Features: Input variables derived from the data.\n","    Training Process: Optimizing parameters to reduce error.\n","    Evaluation Metrics: Assessing model performance (e.g., accuracy, precision).\n","4.  How does loss value help in determining whether the model is good or not?\n","-   The loss value quantifies how far the model's predictions are from the actual values. A lower loss indicates better performance. However, other metrics like accuracy or F1-score are also essential for evaluation, depending on the problem.\n","5.  What are continuous and categorical variables?\n","-   Continuous variables have numerical values that can take any value within a range (e.g., height, weight).\n","    Categorical variables represent discrete categories or groups (e.g., colors, countries).\n","6.  How do we handle categorical variables in Machine Learning? What are the common techniques?\n","-   Common techniques include:\n","    One-Hot Encoding: Converts categories into binary vectors.\n","    Label Encoding: Assigns numeric labels to categories.\n","    Ordinal Encoding: Assigns ordered numeric values.\n","    Target Encoding: Uses mean or probability of a category in the target variable.\n","7.  What do you mean by training and testing a dataset?\n","-    Training Dataset: The portion of the data used to train the model. It teaches the model patterns and relationships.\n","    Testing Dataset: A separate portion used to evaluate the model's performance on unseen data, ensuring generalizability.\n","8.  What is sklearn.preprocessing??\n","-   sklearn.preprocessing is a module in Scikit-Learn that provides tools for feature transformation. Examples include scaling numerical data, encoding categorical variables, normalizing features, and handling missing values.\n","9.  What is a Test set?\n","-   A test set is a portion of the data reserved for evaluating the model's performance after training. It helps assess how well the model generalizes to unseen data.\n","10. How do we split data for model fitting (training and testing) in Python?\n","-   You can use the train_test_split() function from Scikit-Learn's model_selection module:\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","     How do you approach a Machine Learning problem?\n","-   Understand the Problem: Define the goal and requirements.\n","    Collect Data: Gather relevant datasets.\n","    Feature Engineering: Select and create features.\n","    Model Building: Choose and train algorithms.\n","11. Why do we have to perform EDA before fitting a model to the data?\n","-   EDA helps understand the data, detect anomalies, identify relationships between variables, and guide preprocessing steps like feature scaling or handling missing values. It ensures the dataset is clean and suitable for model building.\n","12. What is correlation?\n","-   Correlation quantifies the relationship between two variables and is measured by the correlation coefficient (ranges from -1 to +1).\n","13. What does negative correlation mean?\n","-   Negative correlation implies that as one variable increases, the other decreases.\n","14. How can you find correlation between variables in Python?\n","-   import pandas as pd\n","    correlation_matrix = df.corr()\n","    print(correlation_matrix)\n","15. What is causation? Explain difference between correlation and causation with an example.\n","-   Causation implies a cause-and-effect relationship between variables.\n","    Correlation only measures association, without implying cause.\n","    Example:\n","    Correlation: Ice cream sales and drowning incidents are positively correlated.\n","    Causation: Warm weather increases both ice cream sales and swimming activities.\n","16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n","-   An optimizer adjusts the model's parameters to minimize the loss function:\n","    Gradient Descent: Updates weights iteratively.\n","    Adam: Adaptive learning rates (default for deep learning).\n","    RMSProp: Handles momentum for faster convergence.\n","    Example:\n","    optimizer = tf.optimizers.Adam(learning_rate=0.001)\n","17. What is sklearn.linear_model?\n","-\n","18. What does model.fit() do? What arguments must be given?\n","-   Purpose: The fit() method is used to train the model by finding patterns in the given dataset. It adjusts the model's internal parameters based on the provided data and target labels.\n","    Arguments:\n","    X: Feature matrix (input data).\n","    y: Target variable (labels).\n","19. What does model.predict() do? What arguments must be given?\n","-   Purpose: After a model is trained, the predict() method is used to make predictions based on new input data.\n","    Arguments:\n","    X: Feature matrix (input data for which predictions are to be made).\n","20. What are continuous and categorical variables?\n","-   Continuous Variables: These are numeric variables that can take any value within a range. Examples: height, weight, temperature.\n","    Categorical Variables: These represent categories or groups and are non-numeric. Examples: gender (male, female), color (red, blue).\n","21. What is feature scaling? How does it help in Machine Learning?\n","-   Definition: Feature scaling is the process of normalizing or standardizing the range of independent variables (features).\n","    Importance:\n","    Ensures all features contribute equally to the model.\n","    Prevents features with larger scales from dominating.\n","    Improves the performance of algorithms that are sensitive to scale, like K-Nearest Neighbors (KNN), Gradient Descent, and Support Vector Machines (SVM).\n","22. How do we perform scaling in Python?\n","-   Standardization (StandardScaler): Rescales data to have a mean of 0 and a standard deviation of 1.\n","    Normalization (MinMaxScaler): Rescales data to fit within a specified range, typically [0, 1].\n","    Example:-\n","    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","    # Standardization\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","\n","    # Normalization\n","    min_max_scaler = MinMaxScaler()\n","    X_normalized = min_max_scaler.fit_transform(X)\n","23. What is sklearn.preprocessing?\n","-   This module in scikit-learn provides tools to preprocess data, such as scaling, normalization, encoding, and generating polynomial features. These preprocessing techniques help models perform better by preparing the data in the most efficient way.\n","24. How do we split data for model fitting (training and testing) in Python?\n","-   Use train_test_split from scikit-learn to split your dataset into training and testing sets.\n","    -Example code:\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    Here:\n","    test_size=0.2 means 20% of the data will be used for testing.\n","    random_state ensures reproducibility.\n","25. Explain data encoding?\n","-   Definition: Data encoding is the process of converting categorical variables into numerical formats so they can be fed into machine learning models.\n","    Types of Encoding:\n","      One-Hot Encoding: Converts categories into binary vectors.\n","        from sklearn.preprocessing import OneHotEncoder\n","        encoder = OneHotEncoder()\n","        encoded_data = encoder.fit_transform(data)\n","      Label Encoding: Assigns a unique integer to each category.\n","        from sklearn.preprocessing import LabelEncoder\n","        label_encoder = LabelEncoder()\n","        encoded_labels = label_encoder.fit_transform(labels)\n","\n"]}]}